{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09a9517-867a-41fa-a0f7-0a4d67a9e5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import random\n",
    "from telethon import TelegramClient, sync\n",
    "\n",
    "# выбор модели\n",
    "model_name = \"llama3.2\" \n",
    "print(\"Используемая модель:\", model_name)\n",
    "\n",
    "\n",
    "#____ФУНКЦИЯ SUMMARY С OLLAMA____\n",
    "def summary_text(text_in):\n",
    "    \"\"\"\n",
    "    Выделяет самую значимую информацию из текста.\n",
    "    Возвращает summary - краткая сводка (1-2 предложения);\n",
    "    список - bullets - несколько ключевых пунктов;\n",
    "    keywords - ключевые слова.\n",
    "    \"\"\"\n",
    "    # первичный запрос\n",
    "    prompt = (\n",
    "        \"Верни СТРОГО JSON в таком формате: {\\\"summary\\\": <2–3 предложения>, \\\"bullets\\\": [3 пункта], \\\"keywords\\\": [5 слов]}.\"\n",
    "        + text_in\n",
    "    )\n",
    "    # ответ трёх проходок с разным seed\n",
    "    text_before = \"\"\n",
    "    for _ in range(3):\n",
    "        seed = random.randint(0, 100)\n",
    "        resp_common = ollama.generate(\n",
    "            model=model_name,\n",
    "            prompt=prompt,\n",
    "            options={\"temperature\": 0.3, \"top_p\": 0.8, \"seed\": seed, \"num_predict\": 300}\n",
    "        )\n",
    "        text = resp_common[\"response\"].strip()\n",
    "        text_before += text + \"\\n\\n\"    \n",
    "    # обработка ответа\n",
    "    prompt_clean = (\n",
    "        \"Из всех summary выдели только наиболее значимую информацию, оставь ≤ 35 слов\"\n",
    "        \"Из всех bullets выдели только наиболее значимые, оставь до ≤ 12 слов\" \n",
    "        \"keywords — только существительные, без дубликатов\"\n",
    "        \"Верни СТРОГО JSON в таком формате: {\\\"summary\\\": <2–3 предложения>, \\\"bullets\\\": [3 пункта], \\\"keywords\\\": [5 слов]}.\"\n",
    "        + text_before\n",
    "    )\n",
    "    resp_clear = ollama.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt_clean,\n",
    "        options={\"temperature\": 0.2, \"top_p\": 0.8, \"seed\": 8, \"num_predict\": 300}\n",
    "    )\n",
    "    text_after = resp_clear[\"response\"].strip()\n",
    "    return text_after\n",
    "\n",
    "\n",
    "#____ПАРСИНГ ВЕБ-САЙТА (основная статья \"Фонтанки\")____\n",
    "\n",
    "# User-Agent\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:88.0) '\n",
    "           'Gecko/20100101 Firefox/88.0'}\n",
    "\n",
    "# ссылка на главную страницу фонтанки\n",
    "url_fontanka = 'https://www.fontanka.ru/'\n",
    "# главная страница фонтанки\n",
    "response_fontanka_main = rq.get(url=url_fontanka, headers=headers)\n",
    "response_fontanka_main.raise_for_status()  # проверка успешности запроса\n",
    "# объект BeautifulSoup главной страницы\n",
    "soup_fontanka = bs(response_fontanka_main.text, 'html.parser')\n",
    "\n",
    "# ссылка на основную статью на главной странице\n",
    "main_art_url = (soup_fontanka.find('article', {'class':'wrap_4T9MT'})).find('a')['href']\n",
    "# страница основной статьи\n",
    "response_main_art = rq.get(url=main_art_url, headers=headers)\n",
    "response_main_art.raise_for_status()  # проверка успешности запроса\n",
    "# объект BeautifulSoup основной статьи\n",
    "soup_main_art = bs(response_main_art.text, 'html.parser')\n",
    "\n",
    "# сбор текста по структуре кода страницы фонтанки\n",
    "text_elements = soup_main_art.select('div[class^=\"uiArticleBlockText\"]')\n",
    "main_art_text = ' '.join([elem.get_text(strip=True) for elem in text_elements])\n",
    "\n",
    "def normalize_text(text):\n",
    "    \"\"\"Нормализует текст с проблемной кодировкой\"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Исправляем распространённые проблемы с кодировкой\n",
    "        normalized = text.encode('latin-1').decode('utf-8', errors='ignore')\n",
    "        return normalized\n",
    "    return text\n",
    "    \n",
    "# декодировка текста основной статьи\n",
    "main_art_text = normalize_text(main_art_text)\n",
    "\n",
    "\n",
    "#____ПАРСИНГ VK (первые 10 постов со стены открытого сообщества)____\n",
    "\n",
    "# переменные \n",
    "token_user = ''   # user_token\n",
    "version = '5.199'\n",
    "domain =  ''      # открытое сообщество\n",
    "\n",
    "# обращение к api vk \n",
    "response = rq.get('https://api.vk.com/method/wall.get',\n",
    "    params={'access_token': token_user,\n",
    "            'v': version,\n",
    "            'domain': domain,\n",
    "            'count': 10,\n",
    "            'filter': 'owner'})\n",
    "# успешность запроса\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # наличие ошибок в ответе VK\n",
    "    if 'error' in data:\n",
    "        print(f\"Ошибка VK API: {data['error']['error_msg']}\")\n",
    "    else:\n",
    "        posts = data['response']['items']\n",
    "        # тексты всех постов\n",
    "        post_texts = []\n",
    "        for post in posts:\n",
    "            text = post.get('text', '').strip()\n",
    "            if text:  # только непустые тексты\n",
    "                post_texts.append(text)\n",
    "# объединение текста всех постов в одну строку\n",
    "all_posts_text = \" \".join(post_texts) \n",
    "\n",
    "\n",
    "#____ПАРСИНГ TG (первые 100 публикаций telegram-канала)____\n",
    "\n",
    "# параметры обращения к API\n",
    "api_id = ''           # api id\n",
    "api_hash = ''         # api hash\n",
    "channel_username = '' # username канала\n",
    "async def main():\n",
    "    async with TelegramClient('session_name', api_id, api_hash) as client:\n",
    "        messages = await client.get_messages(channel_username, limit=100)\n",
    "        post_tg_texts = []  # список для текстов\n",
    "        for message in messages:\n",
    "            if message.text:  # текст есть\n",
    "                post_tg_texts.append(message.text)\n",
    "        return post_tg_texts  # список\n",
    "# тексты публикаций тг\n",
    "tg_texts = await main()\n",
    "# все тексты публикаций в одну строку\n",
    "all_tg_texts = \" \".join(tg_texts) \n",
    "\n",
    "\n",
    "#____ВЫЗОВ___\n",
    "if __name__ == '__main__':\n",
    "    text_font = summary_text(main_art_text)\n",
    "    print(text_font)\n",
    "    text_vk_group = summary_text(all_posts_text)\n",
    "    print(text_vk_group)\n",
    "    text_tg_channel = summary_text(all_tg_texts)\n",
    "    print(text_tg_channel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
