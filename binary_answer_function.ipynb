{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c8ad8f-a297-4bea-b4c6-40816e71cd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import json, re, time\n",
    "import ollama\n",
    "\n",
    "#____ВОПРОС____\n",
    "question_test = \"Стоит ли использовать искусственный интеллект, если с его помощью можно автоматизировать многие процессы, но он не всегда бывает стабилен?\"\n",
    "\n",
    "\n",
    "def binary_answer(question, model_name=\"llama3.2\", temperature=0.2, top_p=0.9, seed=8, num_predict=200):\n",
    "\n",
    "    #____первичная оценка вопроса ollama____\n",
    "    prompt_A = (\n",
    "        \"Сохранив суть вопроса, преобразуй его в более чёткий вопрос - такой, на который можно ответить да/нет и корректно выдели отдельно допущения и критерии вопроса.\\n\"\n",
    "        \"Верни строго один JSON-объект без текста до/после, поля:\\n\"\n",
    "        \"{ \\\"proposition\\\": <строка>, \\\"assumptions\\\": [строки], \\\"criteria\\\": [строки] }.\\n\"\n",
    "        \"Вопрос:\\n\\n\"\n",
    "        + question\n",
    "    )\n",
    "    resp_A = ollama.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt_A,\n",
    "        options={\"temperature\": temperature, \"top_p\": top_p, \"seed\": seed, \"num_predict\": num_predict}\n",
    "    )\n",
    "    text_A = resp_A[\"response\"].strip()\n",
    "    \n",
    "    # распарсить JSON; при неудаче — более строгий повтор\n",
    "    ok_A = False # флаг успешного парсинга\n",
    "    attempt_a = 0  # счётчик попыток\n",
    "    while not ok_A and attempt_a < 3:\n",
    "        attempt_a += 1\n",
    "        try:\n",
    "            data_A = json.loads(text_A)\n",
    "            ok_A = True\n",
    "        except Exception as e:\n",
    "            print(\"Не JSON, более строгий повтор:...\")\n",
    "            prompt_A_strict = (\n",
    "                \"СТРОГО верни валидный JSON без лишних символов. Формат:\\n\"\n",
    "                \"{ \\\"proposition\\\": <строка>, \\\"assumptions\\\": [строки], \\\"criteria\\\": [строки] }.\\n\\nВопрос:\\n\" + text_A\n",
    "            )\n",
    "            resp_A = ollama.generate(\n",
    "                model=model_name,\n",
    "                prompt=prompt_A_strict,\n",
    "                options={\"temperature\": 0.0, \"top_p\": 1.0, \"seed\": seed+attempt_a, \"num_predict\": 200}\n",
    "            ) # seed: seed+attempt - изменённый сид для разнообразия\n",
    "            text_A = resp_A[\"response\"].strip()\n",
    "    # если не получен успешный ответ, используется типизированная заготовка\n",
    "    if not ok_A:\n",
    "        data_A = {\"proposition\": question, \"assumptions\": [\"Наиболее упрощённое рассуждение.\"], \"criteria\": [\"Базовый ответ.\"]}\n",
    "    \n",
    "    #____анализ пропозиции по результатам оценки ollama____\n",
    "    prop, assm, crit = data_A.get(\"proposition\", question), data_A.get(\"assumptions\", []), data_A.get(\"criteria\", [])\n",
    "    context_block = \"\\n\".join(filter(None, [\n",
    "        f\"Пропозиция: {prop}\",\n",
    "        f\"Допущения: {'; '.join(assm)}\" if assm else \"\",\n",
    "        f\"Критерии: {'; '.join(crit)}\" if crit else \"\"\n",
    "    ]))\n",
    "    prompt_B = (\n",
    "        \"Проанализируй пропозицию да/нет кратко по-русски на 2–4 предложения, ссылаясь на критерии/допущения, \"\n",
    "        \"и завершай - VERDICT: YES или VERDICT: NO. Никаких других маркеров после вердикта.\\n\\n\"\n",
    "        + context_block\n",
    "    )\n",
    "    resp_B = ollama.generate(\n",
    "        model=model_name,\n",
    "        prompt=prompt_B,\n",
    "        options={\"temperature\": 0.2, \"top_p\": top_p, \"seed\": seed, \"num_predict\": 240}\n",
    "    )\n",
    "    text_B = resp_B[\"response\"].strip()\n",
    "    \n",
    "    #____приведение вердикта к бинарному формату____\n",
    "    binary = None\n",
    "    verdict = None\n",
    "    # поиск VERDICT: YES/NO\n",
    "    lit = re.search(r\"VERDICT:\\s*(YES|NO)\\b\", text_B, flags=re.IGNORECASE)\n",
    "    if lit:\n",
    "        verdict = lit.group(1).upper()\n",
    "    \n",
    "    # при неудаче повторный запрос на yes/no\n",
    "    attempt_b = 0\n",
    "    while verdict is None and attempt_b < 3:\n",
    "        attempt_b += 1\n",
    "        resp = ollama.generate(\n",
    "            model=model_name,\n",
    "            prompt=\"Ответь строго одним словом на английском: YES или NO. Только это слово. Пропозиция:\\n\\n\" + prop,\n",
    "            options={\"temperature\": 0.0, \"top_p\": 1.0, \"seed\": seed+attempt_b, \"num_predict\": 10}\n",
    "        )\n",
    "        txt = resp[\"response\"].strip()\n",
    "        lit = re.search(r\"\\b(YES|NO)\\b\", txt, flags=re.IGNORECASE)\n",
    "        if lit:\n",
    "            verdict = lit.group(1).upper()\n",
    "    \n",
    "    # YES/NO в 1/0\n",
    "    if verdict == \"YES\":\n",
    "        binary = 1\n",
    "    elif verdict == \"NO\":\n",
    "        binary = 0\n",
    "    \n",
    "    # при неудаче повторный запрос на 1/0\n",
    "    attempt_c = 0\n",
    "    while binary is None and attempt_c < 3:\n",
    "        attempt_c += 1\n",
    "        rule = (\n",
    "            \"Выбери 1 (за) или 0 (против) по пропозиции выше. Если аргументы равны — выбери 0. \"\n",
    "            \"Верни строго одну цифру без текста.\"\n",
    "        )\n",
    "        resp = ollama.generate(\n",
    "            model=model_name,\n",
    "            prompt=rule + \"\\n\\nПропозиция: \" + prop,\n",
    "            options={\"temperature\": 0.0, \"top_p\": 1.0, \"seed\": seed+10+attempt_c, \"num_predict\": 5}\n",
    "        )\n",
    "        txt = resp[\"response\"].strip()\n",
    "        lit_2 = re.search(r\"^(0|1)$\", txt)\n",
    "        if lit_2:\n",
    "            binary = int(lit_2.group(1))\n",
    "    # при неудаче - поиск по всем ответам\n",
    "    if binary is None:\n",
    "        # YES/NO/ДА/НЕТ из всех ответов\n",
    "        text_all = (text_A + \"\\n\" + text_B).lower()\n",
    "        if re.search(r\"\\b(yes|да)\\b\", text_all): binary = 1\n",
    "        if re.search(r\"\\b(no|нет)\\b\", text_all): binary = 0 if binary is None else binary\n",
    "    # при неудаче - последняя попытка строгой оценки моделью\n",
    "    if binary is None:\n",
    "        resp = ollama.generate(\n",
    "            model=model_name,\n",
    "            prompt=\"Верни строго одну цифру: 1 (за) или 0 (против) по пропозиции ниже. Без комментариев.\\n\\n\" + prop,\n",
    "            options={\"temperature\": 0.0, \"top_p\": 1.0, \"seed\": seed+99, \"num_predict\": 5}\n",
    "        )\n",
    "        txt = resp[\"response\"].strip()\n",
    "        lit_3 = re.search(r\"^(0|1)$\", txt)\n",
    "        if lit_3:\n",
    "            binary = int(lit_3.group(1))\n",
    "    # при неудаче - дефолтное значение 0\n",
    "    if binary is None:\n",
    "        binary = 0\n",
    "        \n",
    "    return binary\n",
    "\n",
    "\n",
    "#____ТЕСТ____\n",
    "if __name__ == \"__main__\":\n",
    "    binary_test = binary_answer(question_test)\n",
    "    print(binary_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
